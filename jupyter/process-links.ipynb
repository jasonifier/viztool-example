{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import collections\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = ''\n",
    "assert os.path.isdir(DATA_DIR)\n",
    "\n",
    "fname = 'links.json'\n",
    "fpath = os.path.join(DATA_DIR, fname)\n",
    "assert os.path.isfile(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fpath, 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_node_attr_values(data, node_id, attr_fields=None):\n",
    "    node_attr_dict = dict()\n",
    "    if attr_fields is None or not isinstance(attr_fields, list):\n",
    "        raise ValueError('Must provide metadata attribute fields for node data curation.')\n",
    "    for entity in data:\n",
    "        node_id_val = entity.get(node_id)\n",
    "        attrs = node_attr_dict.get(node_id_val, {})\n",
    "        for field in attr_fields:\n",
    "            values = attrs.get(field, [])\n",
    "            new_value = entity.get(field)\n",
    "            if not new_value is None:\n",
    "                values.append(new_value)\n",
    "            attrs[field] = list(set(values))\n",
    "        node_attr_dict[node_id_val] = attrs\n",
    "    return node_attr_dict\n",
    "\n",
    "\n",
    "def reduce_node_attr_values(data, min_date_field=None, max_date_field=None, delimiter=',', attr_fields=None):\n",
    "    node_lookup = dict()\n",
    "    if attr_fields is None or not isinstance(attr_fields, list):\n",
    "        raise ValueError('Must provide metadata attribute fields for node data curation.')\n",
    "    for node_id, attrs in data.items():\n",
    "        rec = dict()\n",
    "        for field in attr_fields:\n",
    "            values = attrs.get(field, [])\n",
    "            if field == min_date_field:\n",
    "                rec[field] = min(values)\n",
    "                continue\n",
    "            if field == max_date_field:\n",
    "                rec[field] = max(values)\n",
    "                continue\n",
    "            if values:\n",
    "                rec[field] = delimiter.join(values)\n",
    "        node_lookup[node_id] = rec\n",
    "    return node_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node_dict(data):\n",
    "    attr_fields=['user_id', 'name', 'email', 'start_date']\n",
    "    user_data = collect_node_attr_values(\n",
    "        data,\n",
    "        node_id='user_id',\n",
    "        attr_fields=attr_fields\n",
    "    )\n",
    "    node_data = reduce_node_attr_values(\n",
    "        user_data,\n",
    "        min_date_field='start_date',\n",
    "        attr_fields=attr_fields\n",
    "    )\n",
    "    shared_data = list(chain.from_iterable([d.get('shared_data', []) for d in data]))\n",
    "    shared_node_data = None\n",
    "    if shared_data:\n",
    "        shared_attr_fields = ['method', 'value', 'first_activity_date', 'last_activity_date']\n",
    "        shared_user_data = collect_node_attr_values(\n",
    "            shared_data,\n",
    "            node_id='value',\n",
    "            attr_fields=shared_attr_fields\n",
    "        )\n",
    "        shared_node_data = reduce_node_attr_values(\n",
    "            shared_user_data,\n",
    "            min_date_field='first_activity_date',\n",
    "            max_date_field='last_activity_date',\n",
    "            attr_fields=shared_attr_fields\n",
    "        )\n",
    "    if not shared_node_data is None:\n",
    "        node_data.update(shared_node_data)\n",
    "    return node_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_edges(data):\n",
    "    all_edges = []\n",
    "    for entity in data:\n",
    "        v1 = entity.get('user_id')\n",
    "        shared_data = entity.get('shared_data', [])\n",
    "        for rec in shared_data:\n",
    "            v2 = rec.get('value')\n",
    "            if v2 is None:\n",
    "                continue\n",
    "            v3 = rec.get('user_id')\n",
    "            if v3 is None:\n",
    "                # expecting data to have the timestamp field here\n",
    "                edges = [{'source': v1, 'target': v2, 'timestamp': rec['last_activity_date']}]\n",
    "            else:\n",
    "                edges = [\n",
    "                    {'source': v1, 'target': v2, 'timestamp': rec['last_activity_date']},\n",
    "                    {'source': v2, 'target': v3, 'timestamp': rec['last_activity_date']}\n",
    "                ]\n",
    "            all_edges.extend(edges)\n",
    "    return all_edges\n",
    "\n",
    "\n",
    "def dedupe_edges(edges):\n",
    "    edge_set = set()\n",
    "    deduped_edges = []\n",
    "    for edge in edges:\n",
    "        t1 = (edge['source'], edge['target'], edge['timestamp'])\n",
    "        t2 = (edge['target'], edge['source'], edge['timestamp'])\n",
    "        if t1 in edge_set:\n",
    "            continue\n",
    "        else:\n",
    "            edge_set.add(t1)\n",
    "            edge_set.add(t2)\n",
    "            deduped_edges.append(edge)\n",
    "    return deduped_edges\n",
    "\n",
    "\n",
    "def apply_node_attributes(\n",
    "    edges,\n",
    "    node_dict={},\n",
    "    color_dict={},\n",
    "    labels=('source', 'target')\n",
    "):\n",
    "    edge_table = []\n",
    "    for edge in edges:\n",
    "        for label in labels:\n",
    "            attrs = node_dict.get(edge[label], {})\n",
    "            if attrs:\n",
    "                edge[f\"{label}_attrs\"] = attrs\n",
    "            edge[f\"{label}_color\"] = color_dict.get(edge[label], 'gray')\n",
    "        edge_table.append(edge)\n",
    "    return edge_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling_dict = collections.defaultdict(list)\n",
    "\n",
    "# for edge in edges:\n",
    "#     for label in ['source', 'target']:\n",
    "#         id_value = edge[label]\n",
    "#         labeling_dict[id_value].append(label)\n",
    "\n",
    "# color_map = {'source & target': 'red', 'source': 'yellow', 'target': 'gray'}\n",
    "# color_dict = dict(labeling_dict)\n",
    "\n",
    "# for node_id in color_dict:\n",
    "#     counts = collections.Counter(color_dict.get(node_id))\n",
    "#     res = ' & '.join(sorted(list(dict(counts).keys())))\n",
    "#     color_dict[node_id] = color_map.get(res, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   ### METHODOLOGY ###\n",
    "\n",
    "# 1. Build the edges from source data\n",
    "# 2. De-duplicate edge data, reduce redundant info\n",
    "# 3. Apply node attributes and/or color labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = build_edges(data)\n",
    "\n",
    "edge_table = apply_node_attributes(\n",
    "    dedupe_edges(edges),\n",
    "    node_dict=create_node_dict(data)\n",
    ")\n",
    "\n",
    "edge_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
